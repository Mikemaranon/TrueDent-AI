{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f607918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall tensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_img, img_to_array\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-win_amd64.whl (375.7 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0\n",
      "  Downloading numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard~=2.19.0\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\javie\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\javie\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (57.4.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.73.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\javie\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (4.14.0)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.14.0-cp310-cp310-win_amd64.whl (2.9 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\javie\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (25.0)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.16.0-cp310-cp310-win_amd64.whl (304 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Collecting namex\n",
      "  Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl (105 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\javie\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, numpy, MarkupSafe, markdown-it-py, wheel, werkzeug, urllib3, tensorboard-data-server, rich, protobuf, optree, namex, ml-dtypes, markdown, idna, h5py, grpcio, charset-normalizer, certifi, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard, requests, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado: 'C:\\\\Users\\\\javie\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libscipy_openblas64_-13e2df515630b4a41f92893938845698.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\javie\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Paso 1: Cargar librer√≠as necesarias\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "%pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38053152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóÇÔ∏è Paso 2: Cargar etiquetas desde el JSON\n",
    "with open(\"resultados_dientes.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convertir a listas\n",
    "imagenes = []\n",
    "etiquetas = []\n",
    "\n",
    "for nombre, atributos in data.items():\n",
    "    path = os.path.join(\"src\", nombre)  # Ruta relativa a las im√°genes\n",
    "    if os.path.exists(path):\n",
    "        imagenes.append(path)\n",
    "        etiquetas.append(atributos[\"salud\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñºÔ∏è Paso 3: Cargar im√°genes y convertir a arrays\n",
    "X = []\n",
    "for path in imagenes:\n",
    "    img = load_img(path, target_size=(128, 128))  # Redimensionamos\n",
    "    img_array = img_to_array(img) / 255.0         # Normalizamos\n",
    "    X.append(img_array)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(etiquetas)\n",
    "print(f\"Im√°genes cargadas: {X.shape}, Etiquetas: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7161e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÇÔ∏è Paso 4: Dividir en entrenamiento y validaci√≥n\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815988bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Paso 5: Definir la CNN\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Para clasificaci√≥n binaria\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6294aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Paso 6: Compilar y entrenar\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Paso 7: Evaluar y visualizar resultados\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validaci√≥n')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Precisi√≥n')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluaci√≥n final\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Precisi√≥n final: {acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
